pipeline {
    agent {
        docker {
            image 'node:14.18.2'
        }
    }
    environment {
        ENVIRONMENT    = 'UAT'
        S3_CREDENTIAL  = 'AWS-CRE'
        S3_REGION      = 'us-east-1'
        BUCKET_NAME    = 'S3://test-zip-file'
        WORKSPACE_PATH = '/var/jenkins_home/workspace/Buggodie-FE-uat'
    }
    options {
        disableConcurrentBuilds()
        durabilityHint('PERFORMANCE_OPTIMIZED') //MAX_SURVIVABILITY or SURVIVABLE_NONATOMIC
    }
    stages {
        stage ('install packages') {
            steps {
                echo '+++++++++++++++++++++ install packages ++++++++++++++++++++'
                //install package from package.json
                sh 'npm install'
            }
        }
        stage ('build') {
            steps {
                echo '+++++++++++++++++++++++++++ building +++++++++++++++++++++++'
                //Running a job
                sh 'CI=false npm run build'
            }
        }
        stage ('install AWS CLI') {
            steps {
                echo '++++++++++++++++++++++ install AWS CLI ++++++++++++++++++++++++'
                sh 'apt-get update'
                sh 'apt install python3-pip -y'
                sh 'pip3 install awscli --upgrade'
            }
        }
        stage ('deploy to AWS S3 ') {
            steps {
                deployToS3 (ENVIRONMENT)
                }
            }
        }
    }
    post {
        success {
            echo 'WELL DONE!!!!!'
            bitbucketStatusNotify (buildState:'SUCCESSFUL')
        }
        failure {
            echo 'FAILED'
            bitbucketStatusNotify (buildState: 'FAILED')
        }
    }

def deployToS3 (environment) {
    echo '++++++++++++++++++++ Deploy frontend to AWS S3 +++++++++++++++++++++'
    withAWS(credentials: S3_CREDENTIAL, region: S3_REGION) {
    //Empty the UAT bucket
    //sh 'aws s3 rm "${BUCKET_NAME}" --recursive'
    //copy the static files from workspace to AWS S3 bucket
    sh 'aws s3 cp "${WORKSPACE_PATH}" "${BUCKET_NAME}"'
    }
}